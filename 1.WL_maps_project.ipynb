{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1beb83b2",
   "metadata": {},
   "source": [
    "# *Weak lensing* maps from Takahashi et al. simulations\n",
    "\n",
    "This notebooks converts binary data and gets map information for weak lensing convergence and galactic *shear*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65e4f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import healpy as hp\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ca956b",
   "metadata": {},
   "source": [
    "## Script to automatically download data files (inputs) from the url of Takahashi et al. \n",
    "http://cosmo.phys.hirosaki-u.ac.jp/takahasi/allsky_raytracing/nres12.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e532a601-cae2-4280-ae7b-0b66e83fb068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import time\n",
    "         # http://cosmo.phys.hirosaki-u.ac.jp/takahasi/allsky_raytracing/sub1/nres12/allskymap_nres12r010.zs1.mag.dat\n",
    "\n",
    "# defining the url string as the first part of the link\n",
    "string1 = 'http://cosmo.phys.hirosaki-u.ac.jp/takahasi/allsky_raytracing/sub1/nres12/allskymap_nres12r'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a83025e-71ee-4dcf-9be7-81c15be3a862",
   "metadata": {},
   "source": [
    "Select the range of realizations you want to use (depending on computer capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "143e6273",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 785.5836420059204\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for i in range(10,15): # 108 realizations in total (JUST ONE z each)\n",
    "    if i < 10:\n",
    "        datafiles_url = string1 +'00'+ str(i)+'.zs1.mag.dat'\n",
    "        local_file = 'allskymap_nres12r00'+str(i)+'.zs1.mag.dat' # downloads and save in the current directory with the name given\n",
    "        urllib.request.urlretrieve(datafiles_url, local_file)\n",
    "    if 10 <= i <= 99:\n",
    "        datafiles_url = string1 +'0'+ str(i)+'.zs1.mag.dat'\n",
    "        # print(datafiles_url)\n",
    "        # print(datafiles_url == 'http://cosmo.phys.hirosaki-u.ac.jp/takahasi/allsky_raytracing/sub1/nres12/allskymap_nres12r011.zs1.mag.dat')\n",
    "\n",
    "        local_file = 'allskymap_nres12r0'+str(i)+'.zs1.mag.dat'\n",
    "        urllib.request.urlretrieve(datafiles_url, local_file)\n",
    "    if 99 < i:\n",
    "        datafiles_url = string1 + str(i)+'.zs1.mag.dat'\n",
    "        local_file = 'allskymap_nres12r'+str(i)+'.zs1.mag.dat'\n",
    "        urllib.request.urlretrieve(datafiles_url, local_file)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('Time:', end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252ed295",
   "metadata": {},
   "source": [
    "# Constructing an array from data in *binary* file\n",
    "\n",
    "From **rxxx.zs##.mag.dat** file takes information in order to define the next arrays:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6b947b",
   "metadata": {},
   "source": [
    "### Reading binary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ea74c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_experiment(filename, num_realization):\n",
    "    # define array\n",
    "    skip = [0, 536870908, 1073741818, 1610612728, 2147483638, 2684354547, 3221225457]\n",
    "    load_blocks = [skip[i+1]-skip[i] for i in range(0, 6)] # array of shape (6, ) of blocks for __??__ (values)\n",
    "    \n",
    "    with open(filename, 'rb') as f:  # allows simplifying writing\n",
    "        rec = np.fromfile(f, dtype='uint32', count=1)[0]  # define array of specific variable type \n",
    "        nside = np.fromfile(f, dtype='int32', count=1)[0] # (but now in particular just takes a single item (count=1 -> just one, count=-1 -> all))\n",
    "        npix = np.fromfile(f, dtype='int64', count=1)[0]  # and takes the index [0], so it's almost like an individual float (confirmed w/ type)\n",
    "        rec = np.fromfile(f, dtype='uint32', count=1)[0]\n",
    "        print(\"nside:{} npix:{}\".format(nside, npix))     # prints the corresponding N_side = 4096\n",
    "\n",
    "        rec = np.fromfile(f, dtype='uint32', count=1)[0]  # why again?\n",
    "\n",
    "        ############  CONVERGENCE part ############\n",
    "\n",
    "#         kappa = np.array([])    #empty array\n",
    "#         r = npix                # redefine the previous variable from f\n",
    "\n",
    "#         for i, l in enumerate(load_blocks):  # similar to for+range but with an iterator (two args: counter, values)\n",
    "#             blocks = min(l, r)  # define the min. between the **values of load_blocks** and **num. pix.**\n",
    "#             load = np.fromfile(f, dtype='float32', count=blocks) # now takes n=blocks count (# of items)\n",
    "#             np.fromfile(f, dtype='uint32', count=2) # takes 2 items from f\n",
    "#             kappa = np.append(kappa, load) # add these values to the initial empty array\n",
    "#             r = r-blocks # takes away the minimum\n",
    "\n",
    "#             if r == 0:  # we avoid the case r=0\n",
    "#                 break\n",
    "#             elif r > 0 and i == len(load_blocks)-1:\n",
    "#                 load = np.fromfile(f, dtype='float32', count=r)  # def. array of 'r' elements\n",
    "#                 np.fromfile(f, dtype='uint32', count=2)\n",
    "#                 kappa = np.append(kappa, load)\n",
    "\n",
    "        ############  SHEAR part (1) ############\n",
    "\n",
    "        gamma1 = np.array([])\n",
    "        r = npix\n",
    "\n",
    "        for i, l in enumerate(load_blocks):\n",
    "            blocks = min(l, r)\n",
    "            load = np.fromfile(f, dtype='float32', count=blocks)\n",
    "            np.fromfile(f, dtype='uint32', count=2)\n",
    "            gamma1 = np.append(gamma1, load)\n",
    "            r = r-blocks\n",
    "            if r == 0:\n",
    "                break\n",
    "            elif r > 0 and i == len(load_blocks)-1:\n",
    "                load = np.fromfile(f, dtype='float32', count=r)\n",
    "                np.fromfile(f, dtype='uint32', count=2)\n",
    "                gamma1 = np.append(gamma1, load)\n",
    "\n",
    "        ############  SHEAR part (2) ############\n",
    "\n",
    "        gamma2 = np.array([])\n",
    "        r = npix\n",
    "        for i, l in enumerate(load_blocks):\n",
    "            blocks = min(l, r)\n",
    "            load = np.fromfile(f, dtype='float32', count=blocks)\n",
    "            np.fromfile(f, dtype='uint32', count=2)\n",
    "            gamma2 = np.append(gamma2, load)\n",
    "            r = r-blocks\n",
    "            if r == 0:\n",
    "                break\n",
    "            elif r > 0 and i == len(load_blocks)-1:\n",
    "                load = np.fromfile(f, dtype='float32', count=r)\n",
    "                np.fromfile(f, dtype='uint32', count=2)\n",
    "                gamma2 = np.append(gamma2, load)\n",
    "\n",
    "    print('loading completed')\n",
    "    \n",
    "    # name_kappa = 'output_k_' + str(num_realization) + '.fits'\n",
    "    name_gamma1 = 'output_g1_' + str(num_realization) + '.fits'\n",
    "    name_gamma2 = 'output_g2_' + str(num_realization) + '.fits'\n",
    "    \n",
    "    # hp.fitsfunc.write_map(name_kappa, kappa)\n",
    "    hp.fitsfunc.write_map(name_gamma1, gamma1)\n",
    "    hp.fitsfunc.write_map(name_gamma2, gamma2)\n",
    "    \n",
    "    return gamma1, gamma2, npix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1589fee",
   "metadata": {},
   "source": [
    "# Saving data as **fits** files\n",
    "\n",
    "**healpy.fitsfunc.write_map** (*filename, array 'm' to be written as a map)*\n",
    "\n",
    "--> Writes a healpix map into a healpix FITS file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a31a8057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nside:4096 npix:201326592\n",
      "loading completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: AstropyDeprecationWarning: \"clobber\" was deprecated in version 2.0 and will be removed in a future version. Use argument \"overwrite\" instead. [healpy.fitsfunc]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nside:4096 npix:201326592\n",
      "loading completed\n",
      "nside:4096 npix:201326592\n",
      "loading completed\n",
      "nside:4096 npix:201326592\n",
      "loading completed\n",
      "nside:4096 npix:201326592\n",
      "loading completed\n"
     ]
    }
   ],
   "source": [
    "# input file\n",
    "\n",
    "for i in range(10,15): # *** 108 in total. Same as before: choose interval\n",
    "    if i < 10:\n",
    "        filename = 'allskymap_nres12r00'+str(i)+'.zs1.mag.dat'\n",
    "        gamma1, gamma2, npix = make_experiment(filename, i+1)\n",
    "    if 10 <= i <= 99:\n",
    "        filename = 'allskymap_nres12r0'+str(i)+'.zs1.mag.dat'\n",
    "        gamma1, gamma2, npix = make_experiment(filename, i+1)\n",
    "    if 99 < i:\n",
    "        filename = 'allskymap_nres12r'+str(i)+'.zs1.mag.dat'\n",
    "        gamma1, gamma2, npix = make_experiment(filename, i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca0b8ab",
   "metadata": {},
   "source": [
    "## Printing data (individually)\n",
    "\n",
    "This cell shows on screen the *WL* data from the contributions of **convergence and shear** (both components) as\n",
    "\n",
    "\n",
    "| $\\kappa$ | $\\gamma_1$ | $\\gamma_2$ |\n",
    "| --- | --- | --- |\n",
    "| - | - | - |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa213fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I recomend not to print it bc is tooo much :) unnecesary\n",
    "\n",
    "# for i in range (npix):    # just in order to see it (e.g., r107)\n",
    "#         print(i, kappa[i], gamma1[i], gamma2[i]) #, omega[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6121b11",
   "metadata": {},
   "source": [
    "### Deleting initial datafiles (.mag.dat)\n",
    "\n",
    "In order to not having n repeated copies of the same file every time the code is run (it automatically downloads every time its excecuted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4255dfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(10,15): # *** 108 in total again\n",
    "    if i < 10:\n",
    "        os.remove( 'allskymap_nres12r00'+ str(j)+'.zs1.mag.dat')\n",
    "    if 10 <= i <= 99:\n",
    "        os.remove('allskymap_nres12r0'+ str(j)+'.zs1.mag.dat')\n",
    "    if 99 < i:\n",
    "        os.remove('allskymap_nres12r' + str(j)+'.zs1.mag.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796df13e-1900-405c-a53c-1f83351c2742",
   "metadata": {},
   "source": [
    "It's done :) now you can go to the next notebook which computes the 2PCF of shear using these fits maps..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desc-stack",
   "language": "python",
   "name": "desc-stack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
